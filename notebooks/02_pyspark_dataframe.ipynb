{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "022f6925-7844-4d82-8ba8-eae463234478",
   "metadata": {},
   "source": [
    "# Init SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b623fc16-76c2-44e7-9a41-7dfeff53c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark import SparkContext, HiveContext\n",
    "from pyspark.sql import SparkSession, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b3c8dc-ea9f-43b8-ac3b-f321e31f4c12",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('spark.repl.local.jars',\n",
       "  'file:///usr/local/spark-3.3.1-bin-hadoop3/jars/delta-core_2.12-2.2.0.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/hadoop-aws-3.3.2.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/delta-storage-2.2.0.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/aws-java-sdk-1.12.367.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/s3-2.18.41.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/aws-java-sdk-bundle-1.11.1026.jar'),\n",
       " ('spark.hadoop.fs.s3a.connection.ssl.enabled', 'false'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.hadoop.fs.s3a.access.key', 'minio'),\n",
       " ('spark.hadoop.fs.s3a.path.style.access', 'true'),\n",
       " ('spark.app.id', 'app-20230125234836-0002'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.startTime', '1674690515626'),\n",
       " ('spark.jars',\n",
       "  'file:///usr/local/spark-3.3.1-bin-hadoop3/jars/delta-core_2.12-2.2.0.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/hadoop-aws-3.3.2.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/delta-storage-2.2.0.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/aws-java-sdk-1.12.367.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/s3-2.18.41.jar,file:///usr/local/spark-3.3.1-bin-hadoop3/jars/aws-java-sdk-bundle-1.11.1026.jar'),\n",
       " ('spark.driver.port', '38671'),\n",
       " ('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem'),\n",
       " ('spark.app.name', 'pyspark-dataframe-demo-2023-01-25 23:48:33.863224'),\n",
       " ('spark.driver.host', '47da998936c0'),\n",
       " ('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.master', 'spark://spark-master:7077'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.submitTime', '1674690515489'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://47da998936c0:38671/jars/delta-core_2.12-2.2.0.jar,spark://47da998936c0:38671/jars/aws-java-sdk-bundle-1.11.1026.jar,spark://47da998936c0:38671/jars/aws-java-sdk-1.12.367.jar,spark://47da998936c0:38671/jars/delta-storage-2.2.0.jar,spark://47da998936c0:38671/jars/hadoop-aws-3.3.2.jar,spark://47da998936c0:38671/jars/s3-2.18.41.jar'),\n",
       " ('spark.hadoop.fs.s3a.endpoint', 'http://minio:9000'),\n",
       " ('spark.hadoop.fs.s3a.secret.key', 'minio123'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.sql.catalog.spark_catalog',\n",
       "  'org.apache.spark.sql.delta.catalog.DeltaCatalog')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(\"pyspark-dataframe-demo-{}\".format(datetime.today()))\n",
    "        .master(\"spark://spark-master:7077\")      \n",
    "        .getOrCreate())\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "spark.sparkContext.getConf().getAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d22b2-7beb-4ffe-8e97-05a70fba67e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d22f7a00-4276-41ca-bc68-3a187e74bd0a",
   "metadata": {},
   "source": [
    "# Create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95203fef-0e9c-4455-b54d-8d2c814ca58a",
   "metadata": {},
   "source": [
    "## By loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d94380-b1d5-46a3-9e3c-69cc5e869049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+\n",
      "|        Plant Name|Rooting Depth|\n",
      "+------------------+-------------+\n",
      "|         Artichoke|            D|\n",
      "|           Arugula|            S|\n",
      "|         Asparagus|            D|\n",
      "|       Beans, bush|            M|\n",
      "|Beans, lima (bush)|            D|\n",
      "|       Beans, pole|            M|\n",
      "|             Beets|            M|\n",
      "|          Broccoli|            S|\n",
      "|   Brussel sprouts|            S|\n",
      "|           Cabbage|            S|\n",
      "|           Carrots|            M|\n",
      "|       Cauliflower|            S|\n",
      "|            Celery|            S|\n",
      "|             Chard|            M|\n",
      "|           Edamame|            M|\n",
      "|              Corn|            S|\n",
      "|          Cucumber|            M|\n",
      "|          Eggplant|            M|\n",
      "|            Endive|            S|\n",
      "|            Garlic|            S|\n",
      "+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_plants = spark.read.format(\"csv\").load(\"s3a://warehouse/plants.csv\", header=True)\n",
    "df_plants.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc3ed14-ca5a-4bb2-9265-7d0d34ab3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "df_plants.write.mode(\"overwrite\")\n",
    "    .option(\"compression\", \"snappy\")\n",
    "    .option(\"path\", \"s3a://warehouse/plants.parquet\")\n",
    "    .format(\"parquet\")\n",
    "    .saveAsTable(\"plants\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f1479-5c9c-4a63-9f2f-208ebe9c42ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e8544f-7d84-4157-b358-90bded246604",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "652d39e6-370d-4358-9453-a1389a00d479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7323c167-ab04-4793-84c6-eb0e461e938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|   plants|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a113c496-e491-407b-83f6-3c5ef3714781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+\n",
      "|        Plant Name|Rooting Depth|\n",
      "+------------------+-------------+\n",
      "|         Artichoke|            D|\n",
      "|           Arugula|            S|\n",
      "|         Asparagus|            D|\n",
      "|       Beans, bush|            M|\n",
      "|Beans, lima (bush)|            D|\n",
      "|       Beans, pole|            M|\n",
      "|             Beets|            M|\n",
      "|          Broccoli|            S|\n",
      "|   Brussel sprouts|            S|\n",
      "|           Cabbage|            S|\n",
      "|           Carrots|            M|\n",
      "|       Cauliflower|            S|\n",
      "|            Celery|            S|\n",
      "|             Chard|            M|\n",
      "|           Edamame|            M|\n",
      "|              Corn|            S|\n",
      "|          Cucumber|            M|\n",
      "|          Eggplant|            M|\n",
      "|            Endive|            S|\n",
      "|            Garlic|            S|\n",
      "+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM plants\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "077e4f41-0317-4af4-961f-cf0aca3b6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|number_of_records|\n",
      "+-----------------+\n",
      "|               21|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) AS number_of_records FROM plants\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b136f-13a0-45de-ad10-c2670bfa6ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
