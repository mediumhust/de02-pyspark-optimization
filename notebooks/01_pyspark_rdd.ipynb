{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9b93dc-97d4-4296-8fc5-2ea73100187f",
   "metadata": {},
   "source": [
    "# Check MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6927363-ac1c-4de1-ac26-c21b5225d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting minio\n",
      "  Downloading minio-7.1.13-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting delta-spark==2.2.0\n",
      "  Downloading delta_spark-2.2.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pyspark<3.4.0,>=3.3.0 in /usr/local/spark-3.3.0-bin-hadoop3/python (from delta-spark==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from delta-spark==2.2.0) (4.11.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.8/site-packages (from minio) (2022.9.24)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.8/site-packages (from minio) (1.26.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=1.0.0->delta-spark==2.2.0) (3.9.0)\n",
      "Collecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py4j, minio, delta-spark\n",
      "Successfully installed delta-spark-2.2.0 minio-7.1.13 py4j-0.10.9.5\n"
     ]
    }
   ],
   "source": [
    "!pip install minio delta-spark==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b81beb-3b7e-4001-a6a8-962312dff812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59a8874-f0e7-4c62-a393-4eef43aa00b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warehouse exists\n"
     ]
    }
   ],
   "source": [
    "client = Minio(\n",
    "    \"minio:9000\",\n",
    "    access_key=\"minio\",\n",
    "    secret_key=\"minio123\",\n",
    "    secure=False\n",
    ")\n",
    "\n",
    "bucket = \"warehouse\"\n",
    "if client.bucket_exists(bucket):\n",
    "    print(f\"{bucket} exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30647709-5bc4-496b-9af4-9194bc605be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "022f6925-7844-4d82-8ba8-eae463234478",
   "metadata": {},
   "source": [
    "# Init SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b623fc16-76c2-44e7-9a41-7dfeff53c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b3c8dc-ea9f-43b8-ac3b-f321e31f4c12",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('spark.driver.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.files',\n",
       "  'file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,file:///home/jovyan/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,file:///home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,file:///home/jovyan/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,file:///home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar'),\n",
       " ('spark.app.submitTime', '1674636025189'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,/home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,/home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,/home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,/home/jovyan/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,/home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar'),\n",
       " ('spark.jars',\n",
       "  'file:///home/jovyan/.ivy2/jars/io.delta_delta-core_2.12-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,file:///home/jovyan/.ivy2/jars/io.delta_delta-storage-2.2.0.jar,file:///home/jovyan/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,file:///home/jovyan/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,file:///home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar'),\n",
       " ('spark.hadoop.fs.s3a.path.style.access', 'True'),\n",
       " ('spark.master', 'spark://spark-master:7077'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.startTime', '1674636025418'),\n",
       " ('spark.driver.port', '40329'),\n",
       " ('spark.hadoop.fs.s3a.endpoint', 'minio:9000'),\n",
       " ('spark.hadoop.fs.s3a.access.key', 'minio'),\n",
       " ('spark.app.id', 'app-20230125084026-0003'),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://b368514570ff:40329/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,spark://b368514570ff:40329/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,spark://b368514570ff:40329/jars/org.antlr_antlr4-runtime-4.8.jar,spark://b368514570ff:40329/jars/io.delta_delta-core_2.12-2.2.0.jar,spark://b368514570ff:40329/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,spark://b368514570ff:40329/jars/io.delta_delta-storage-2.2.0.jar'),\n",
       " ('spark.app.initial.file.urls',\n",
       "  'spark://b368514570ff:40329/files/org.antlr_antlr4-runtime-4.8.jar,spark://b368514570ff:40329/files/io.delta_delta-core_2.12-2.2.0.jar,spark://b368514570ff:40329/files/io.delta_delta-storage-2.2.0.jar,spark://b368514570ff:40329/files/org.apache.hadoop_hadoop-aws-3.3.2.jar,spark://b368514570ff:40329/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,spark://b368514570ff:40329/files/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.hadoop.fs.s3a.connection.ssl.enabled', 'False'),\n",
       " ('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem'),\n",
       " ('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension'),\n",
       " ('spark.app.name', 'pyspark-rdd-demo-2023-01-25 08:39:43.855840'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.jars.packages',\n",
       "  'io.delta:delta-core_2.12:2.2.0,org.apache.hadoop:hadoop-aws:3.3.2'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.hadoop.fs.s3a.secret.key', 'minio123'),\n",
       " ('spark.driver.host', 'b368514570ff'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.sql.catalog.spark_catalog',\n",
       "  'org.apache.spark.sql.delta.catalog.DeltaCatalog')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(\"pyspark-rdd-demo-{}\".format(datetime.today()))\n",
    "        .master(\"spark://spark-master:7077\")\n",
    "        .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.2.0,org.apache.hadoop:hadoop-aws:3.3.2\")\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", \"minio:9000\")\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\")\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\")\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True)\n",
    "        .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", False)\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")         \n",
    "        .getOrCreate())\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "spark.sparkContext.getConf().getAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14869d2-772c-4120-a37d-cd4d21790016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b368514570ff:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-rdd-demo-2023-01-25 08:39:43.855840</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://spark-master:7077 appName=pyspark-rdd-demo-2023-01-25 08:39:43.855840>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f7a00-4276-41ca-bc68-3a187e74bd0a",
   "metadata": {},
   "source": [
    "# Create RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95203fef-0e9c-4455-b54d-8d2c814ca58a",
   "metadata": {},
   "source": [
    "## By loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70ca7bb-0817-46a9-8e2e-927444f69193",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.range(500).write.format(\"delta\").save(\"s3a://warehouse/demo1\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28d6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdd92620-5109-4638-bd75-c5024c876e80",
   "metadata": {},
   "source": [
    "## By using parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418feb28-01db-4938-ac5e-ac5a1f3701a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4dd391e-67fa-4897-82f2-c1fe96972965",
   "metadata": {},
   "source": [
    "# RDD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60076a41-54ee-4e3c-9954-d47d96de5666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddf5853e-cb48-421a-b0c4-64dd43326ab5",
   "metadata": {},
   "source": [
    "# Caching RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15be3b0-4d5f-4112-8ad8-4806adc3131e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
